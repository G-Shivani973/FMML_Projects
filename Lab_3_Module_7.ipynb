{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVRa26lKGCZia2FCGFjgg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-Shivani973/FMML_Projects/blob/main/Lab_3_Module_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. How exactly does matrix factorization help us in the recommendation procedure? Why can we not simply model the user-movie matrix?"
      ],
      "metadata": {
        "id": "0HJd6wyMeeBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix factorization is a powerful method utilized in recommendation systems to address the challenges posed by sparse data and to unveil latent factors that depict underlying patterns or features within the data. Here is an explanation of its functionality and significance:\n",
        "\n",
        "1. **Sparse Data**: In a typical recommendation setting, a vast user-item matrix is present where a majority of the entries are absent due to users interacting with only a limited number of items. For instance, in a movie recommendation platform, most users have rated only a fraction of the available movies. This sparsity complicates the direct modeling of user preferences or item characteristics.\n",
        "\n",
        "2. **Dimensionality Reduction**: Matrix factorization aids in reducing the dimensionality of the original user-item matrix by approximating it as the product of two lower-dimensional matrices. These matrices embody latent factors that capture the fundamental structure of the data. For example, in a movie recommendation system, the latent factors could represent attributes like genre, actor, director, etc., for movies, and users' preferences for these attributes.\n",
        "\n",
        "3. **Discovery of Latent Factors**: Through decomposing the original matrix into lower-dimensional matrices, matrix factorization enables the revelation of concealed patterns or latent factors in the data. For instance, certain movies may be linked with specific genres or themes, and certain users may exhibit preferences for those genres or themes. Matrix factorization aids in implicitly uncovering these associations.\n",
        "\n",
        "4. **Personalization and Recommendations**: Once the latent factors are derived via matrix factorization, they can be utilized to provide personalized recommendations for users. By examining the latent factors linked with users and items, the system can predict the likelihood of a user enjoying an item they have not interacted with based on similar users' preferences or items the user has favored previously.\n",
        "\n",
        "5. **Scalability and Efficiency**: Matrix factorization techniques are frequently computationally efficient."
      ],
      "metadata": {
        "id": "kdS27IRoeeDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.What do the rows of the matrix  T  represent? (Definition of  T  is above in the introduction to LSI)."
      ],
      "metadata": {
        "id": "vPceNfxSejAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Latent Semantic Indexing (LSI), the transformed term-document matrix after Singular Value Decomposition (SVD) is denoted as matrix \\( T \\). In the context of LSI:\n",
        "\n",
        "- The documents in the corpus are represented by the rows of matrix \\( T \\).\n",
        "- The latent semantic dimensions or concepts discovered through the SVD process are represented by the columns of matrix \\( T \\).\n",
        "\n",
        "Each entry in matrix \\( T \\) indicates the strength of association between a document and a latent semantic dimension. These entries reflect the importance or weight of each latent semantic dimension in representing the content of each document in the corpus.\n",
        "\n",
        "The goal of LSI is to capture the underlying structure in the term-document matrix by reducing its dimensionality through SVD. The resulting matrix \\( T \\) offers a more concise representation of the documents in terms of the discovered latent semantic dimensions. This compact representation can be utilized for various natural language processing tasks, including information retrieval, document clustering, and document similarity measurement."
      ],
      "metadata": {
        "id": "4TWF8gc_enjh"
      }
    }
  ]
}